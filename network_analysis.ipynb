{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/5niz3POBptsf+mclgpHs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waterta0115/LDA_graduattion_thesis/blob/main/network_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "def find_threshold_by_count(matrix, target_edge_count):\n",
        "\n",
        "    indices = np.triu_indices(len(matrix), k=1)\n",
        "    edge_weights = matrix[indices]\n",
        "\n",
        "    existing_edges = edge_weights[edge_weights > 0]\n",
        "\n",
        "    if len(existing_edges) == 0:\n",
        "        print(\"Error: No edges exist in the graph.\")\n",
        "        return 0.0\n",
        "\n",
        "    # --- 2. Threshold Calculation Logic ---\n",
        "    sorted_weights = np.sort(existing_edges)\n",
        "    total_edges = len(existing_edges)\n",
        "\n",
        "    if target_edge_count >= total_edges:\n",
        "        print(\"Warning: The specified number of edges is greater than or equal to the total number of edges. All edges will be kept.\")\n",
        "        tau = 0.0 # To keep all edges, set to 0 (or a value smaller than the minimum)\n",
        "\n",
        "        calculated_cut_percentage = 0.0\n",
        "    elif target_edge_count <= 0:\n",
        "        print(\"Warning: The specified number of edges is 0 or less. All edges will be removed.\")\n",
        "        tau = sorted_weights[-1] + 1.0 # Set higher than the maximum value\n",
        "        calculated_cut_percentage = 100.0\n",
        "    else:\n",
        "        cutoff_index = total_edges - target_edge_count - 1\n",
        "\n",
        "        # Determine the threshold (typically, values greater than this are kept)\n",
        "        tau = sorted_weights[cutoff_index]\n",
        "\n",
        "        calculated_cut_percentage = (cutoff_index + 1) / total_edges * 100\n",
        "\n",
        "    # --- 3. Verification of Results ---\n",
        "    actual_kept_edges = np.sum(existing_edges > tau)\n",
        "\n",
        "    print(f\"--- Threshold Calculation Result (Target Count Mode) ---\")\n",
        "    print(f\"Total edges (greater than 0) : {total_edges}\")\n",
        "    print(f\"Target number of edges to keep : {target_edge_count}\")\n",
        "    print(f\"Determined threshold (τ)    : {tau:.7f}\")\n",
        "    print(f\"---\")\n",
        "    print(f\"Actual edges kept    : {actual_kept_edges} (those greater than threshold {tau:.4f})\")\n",
        "    print(f\"Actual percentage kept        : {actual_kept_edges / total_edges * 100:.2f}%\")\n",
        "    print(f\"Calculated cut percentage      : {calculated_cut_percentage:.2f}%\")\n",
        "\n",
        "    if actual_kept_edges != target_edge_count:\n",
        "        print(f\"*Note: Due to edges with identical weights, the target count ({target_edge_count}) was not perfectly matched.\")\n",
        "\n",
        "    # --- 4. Create and Visualize the Cumulative Probability Plot (CDF) ---\n",
        "    y_cumulative = np.arange(1, len(sorted_weights) + 1) / len(sorted_weights)\n",
        "\n",
        "    plt.figure(figsize=(12, 7))\n",
        "    plt.plot(sorted_weights, y_cumulative, color='blue', label='Cumulative Distribution (CDF)')\n",
        "\n",
        "    # --- 5. Display the Determined Threshold on the Graph ---\n",
        "    plt.axvline(x=tau, color='red', linestyle='--',\n",
        "                label=f'Threshold τ = {tau:.7f}')\n",
        "\n",
        "    plt.axhline(y=calculated_cut_percentage / 100.0, color='red', linestyle=':',\n",
        "                label=f'Cutoff Probability {calculated_cut_percentage/100:.2f} (Removes bottom {calculated_cut_percentage:.1f}%)')\n",
        "\n",
        "    # Mark the intersection point\n",
        "    plt.plot(tau, calculated_cut_percentage / 100.0, 'ro')\n",
        "\n",
        "    plt.title(f'CDF of Edge Weights (Targeting top {target_edge_count} edges)',fontsize=20)\n",
        "    plt.xlabel('Edge Weight (Value of element)',fontsize=20)\n",
        "    plt.ylabel('Cumulative Probability',fontsize=20)\n",
        "    plt.legend(fontsize=20)\n",
        "    plt.grid(True, which=\"both\", ls=\"--\", alpha=0.5)\n",
        "\n",
        "    plt.gca().yaxis.set_major_formatter(ticker.PercentFormatter(xmax=1.0))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return tau"
      ],
      "metadata": {
        "id": "9YBTeIq8PDBA"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adj_matrix_(topic_term_dists,vocab,threshold):\n",
        "    co_occurrence = np.dot(topic_term_dists.T, topic_term_dists)\n",
        "    co_matrix = pd.DataFrame(co_occurrence, index=vocab, columns=vocab)\n",
        "    threshold = np.quantile(co_matrix.values, threshold)\n",
        "    filtered = co_matrix.mask(co_matrix < threshold, 0)\n",
        "    adj_matrix = filtered.to_numpy(dtype=float)\n",
        "    return adj_matrix"
      ],
      "metadata": {
        "id": "oY_hmHyEPEgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "J1cWsEwQO9xd"
      },
      "outputs": [],
      "source": [
        "def plot_igraph_from_adjacency_deg(\n",
        "    adjacency_matrix,\n",
        "    labels,\n",
        "    layout_type=\"fr\",\n",
        "    vertex_size=30,\n",
        "    edge_width_scale=5,\n",
        "    vertex_label_size=14,\n",
        "    edge_curved=False,\n",
        "    figsize=(8, 8),\n",
        "    edge_threshold=0.0,\n",
        "    vertex_color=\"skyblue\",\n",
        "    edge_color=\"gray\",\n",
        "    top_n_labels=20\n",
        "):\n",
        "    import igraph as ig\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "\n",
        "    # Convert adjacency matrix to numpy array\n",
        "    adj = np.array(adjacency_matrix)\n",
        "    n = adj.shape[0]\n",
        "\n",
        "    # Set edge weights below the threshold to 0\n",
        "    adj = np.where(adj > edge_threshold, adj, 0)\n",
        "\n",
        "    # Create igraph graph\n",
        "    g = ig.Graph.Weighted_Adjacency(adj.tolist(), mode=ig.ADJ_UNDIRECTED, attr=\"weight\", loops=False)\n",
        "    g.vs[\"name\"] = labels\n",
        "\n",
        "    # Remove isolated nodes\n",
        "    isolated_nodes = [v.index for v in g.vs if g.degree(v) == 0.0]\n",
        "    if isolated_nodes:\n",
        "        g.delete_vertices(isolated_nodes)\n",
        "\n",
        "\n",
        "\n",
        "    # Node labels\n",
        "    # Assuming labels = vocab is passed\n",
        "    if \"name\" in g.vs.attributes():\n",
        "        # Copy from g.vs[\"name\"] to g.vs[\"label\"]\n",
        "        g.vs[\"label\"] = g.vs[\"name\"]\n",
        "    else:\n",
        "        # Fallback if \"name\" attribute is not present\n",
        "        g.vs[\"label\"] = [str(i) for i in range(g.vcount())]\n",
        "    # Assign labels only to the top_n_labels nodes with the highest degrees\n",
        "    degrees = g.degree()\n",
        "    top_indices = np.argsort(degrees)[-top_n_labels:]  # Top top_n_labels items\n",
        "    g.vs[\"label\"] = [\n",
        "        g.vs[i][\"label\"] if i in top_indices else \"\" for i in range(g.vcount())\n",
        "    ]\n",
        "    # Layout\n",
        "    layout = g.layout(layout_type)\n",
        "\n",
        "    # Edge width\n",
        "    edge_weights = g.es[\"weight\"] if \"weight\" in g.es.attributes() else [1]*g.ecount()\n",
        "    if len(edge_weights) > 0 and max(edge_weights) > 0:\n",
        "        edge_widths = [edge_width_scale * (w / max(edge_weights)) for w in edge_weights]\n",
        "    else:\n",
        "        edge_widths = [1 for _ in edge_weights]\n",
        "\n",
        "    # Community detection (e.g., Louvain method, fallback to fastgreedy if Louvain not available)\n",
        "    try:\n",
        "        communities = g.community_multilevel(weights=g.es['weight'] if 'weight' in g.es.attributes() else None)\n",
        "    except AttributeError:\n",
        "        # fallback method\n",
        "        communities = g.community_fastgreedy(weights=g.es['weight'] if 'weight' in g.es.attributes() else None).as_clustering()\n",
        "    membership = communities.membership\n",
        "    import matplotlib\n",
        "    cmap = matplotlib.cm.get_cmap('tab20')\n",
        "    num_colors = cmap.N if hasattr(cmap, \"N\") else 20\n",
        "    comm_vertex_colors = [matplotlib.colors.to_hex(cmap(i % num_colors)) for i in membership]\n",
        "    g.vs[\"color\"] = comm_vertex_colors\n",
        "    # Change node size according to node degree\n",
        "    degrees = g.degree()\n",
        "    # Specify minimum and maximum sizes for appropriate scaling\n",
        "    min_size = 20\n",
        "    max_size = 80\n",
        "    # Scaling\n",
        "    if degrees:\n",
        "        min_deg = min(degrees)\n",
        "        max_deg = max(degrees) if max(degrees) != min(degrees) else min(degrees) + 1\n",
        "        # Calculate node size\n",
        "        scaled_sizes = [\n",
        "            min_size + (deg - min_deg) / (max_deg - min_deg) * (max_size - min_size)\n",
        "            for deg in degrees\n",
        "        ]\n",
        "    else:\n",
        "        scaled_sizes = [min_size for _ in g.vs]\n",
        "    g.vs[\"size\"] = scaled_sizes\n",
        "\n",
        "    # Redraw based on node size (node size = degree)\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "    ig.plot(\n",
        "        g,\n",
        "        target=ax,\n",
        "        layout=layout,\n",
        "        vertex_size=g.vs[\"size\"],\n",
        "        vertex_label=g.vs[\"label\"],\n",
        "        vertex_label_size=vertex_label_size,\n",
        "        vertex_color=g.vs[\"color\"],\n",
        "        edge_width=edge_widths,\n",
        "        edge_color=edge_color,\n",
        "        edge_curved=edge_curved,\n",
        "        bbox=(figsize[0]*100, figsize[1]*100),\n",
        "        margin=40,\n",
        "    )\n",
        "    plt.show()\n",
        "    return g,communities"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_igraph_from_adjacency_bet(\n",
        "    adjacency_matrix,\n",
        "    labels,\n",
        "    layout_type=\"fr\",\n",
        "    vertex_size=30,\n",
        "    edge_width_scale=5,\n",
        "    vertex_label_size=14,\n",
        "    edge_curved=False,\n",
        "    figsize=(8, 8),\n",
        "    edge_threshold=0.0,\n",
        "    vertex_color=\"skyblue\",\n",
        "    edge_color=\"gray\",\n",
        "    top_n_labels=20\n",
        "):\n",
        "    import igraph as ig\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "\n",
        "    # Convert adjacency matrix to numpy array\n",
        "    adj = np.array(adjacency_matrix)\n",
        "    n = adj.shape[0]\n",
        "\n",
        "    # Set edge weights below the threshold to 0\n",
        "    adj = np.where(adj > edge_threshold, adj, 0)\n",
        "\n",
        "    # Create igraph graph\n",
        "    g = ig.Graph.Weighted_Adjacency(adj.tolist(), mode=ig.ADJ_UNDIRECTED, attr=\"weight\", loops=False)\n",
        "    g.vs[\"name\"] = labels\n",
        "\n",
        "    # Remove isolated nodes\n",
        "    isolated_nodes = [v.index for v in g.vs if g.degree(v) == 0.0]\n",
        "    if isolated_nodes:\n",
        "        g.delete_vertices(isolated_nodes)\n",
        "\n",
        "\n",
        "\n",
        "    # Node labels\n",
        "    # Assuming labels = vocab is passed\n",
        "    if \"name\" in g.vs.attributes():\n",
        "        # Copy from g.vs[\"name\"] to g.vs[\"label\"]\n",
        "        g.vs[\"label\"] = g.vs[\"name\"]\n",
        "    else:\n",
        "        # Fallback if \"name\" attribute is not present\n",
        "        g.vs[\"label\"] = [str(i) for i in range(g.vcount())]\n",
        "    # Assign labels only to the top_n_labels nodes with the highest betweenness\n",
        "    degrees = g.betweenness()\n",
        "    top_indices = np.argsort(degrees)[-top_n_labels:]  # Top top_n_labels items\n",
        "    g.vs[\"label\"] = [\n",
        "        g.vs[i][\"label\"] if i in top_indices else \"\" for i in range(g.vcount())\n",
        "    ]\n",
        "    # Layout\n",
        "    layout = g.layout(layout_type)\n",
        "\n",
        "    # Edge width\n",
        "    edge_weights = g.es[\"weight\"] if \"weight\" in g.es.attributes() else [1]*g.ecount()\n",
        "    if len(edge_weights) > 0 and max(edge_weights) > 0:\n",
        "        edge_widths = [edge_width_scale * (w / max(edge_weights)) for w in edge_weights]\n",
        "    else:\n",
        "        edge_widths = [1 for _ in edge_weights]\n",
        "\n",
        "    # Community detection (e.g., Louvain method, fallback to fastgreedy if Louvain not available)\n",
        "    try:\n",
        "        communities = g.community_multilevel(weights=g.es['weight'] if 'weight' in g.es.attributes() else None)\n",
        "    except AttributeError:\n",
        "        # fallback method\n",
        "        communities = g.community_fastgreedy(weights=g.es['weight'] if 'weight' in g.es.attributes() else None).as_clustering()\n",
        "    membership = communities.membership\n",
        "    import matplotlib\n",
        "    cmap = matplotlib.cm.get_cmap('tab20')\n",
        "    num_colors = cmap.N if hasattr(cmap, \"N\") else 20\n",
        "    comm_vertex_colors = [matplotlib.colors.to_hex(cmap(i % num_colors)) for i in membership]\n",
        "    g.vs[\"color\"] = comm_vertex_colors\n",
        "    # Change node size according to node betweenness\n",
        "    degrees = g.betweenness()\n",
        "    # Specify minimum and maximum sizes for appropriate scaling\n",
        "    min_size = 20\n",
        "    max_size = 80\n",
        "    # Scaling\n",
        "    if degrees:\n",
        "        min_deg = min(degrees)\n",
        "        max_deg = max(degrees) if max(degrees) != min(degrees) else min(degrees) + 1\n",
        "        # Calculate node size\n",
        "        scaled_sizes = [\n",
        "            min_size + (deg - min_deg) / (max_deg - min_deg) * (max_size - min_size)\n",
        "            for deg in degrees\n",
        "        ]\n",
        "    else:\n",
        "        scaled_sizes = [min_size for _ in g.vs]\n",
        "    g.vs[\"size\"] = scaled_sizes\n",
        "\n",
        "    # Redraw based on node size (node size = betweenness)\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "    ig.plot(\n",
        "        g,\n",
        "        target=ax,\n",
        "        layout=layout,\n",
        "        vertex_size=g.vs[\"size\"],\n",
        "        vertex_label=g.vs[\"label\"],\n",
        "        vertex_label_size=vertex_label_size,\n",
        "        vertex_color=g.vs[\"color\"],\n",
        "        edge_width=edge_widths,\n",
        "        edge_color=edge_color,\n",
        "        edge_curved=edge_curved,\n",
        "        bbox=(figsize[0]*100, figsize[1]*100),\n",
        "        margin=40,\n",
        "    )\n",
        "    plt.show()\n",
        "    return g,communities"
      ],
      "metadata": {
        "id": "H0xrbkjw1JqY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_igraph_from_adjacency_pr(\n",
        "    adjacency_matrix,\n",
        "    labels,\n",
        "    layout_type=\"fr\",\n",
        "    vertex_size=30,\n",
        "    edge_width_scale=5,\n",
        "    vertex_label_size=14,\n",
        "    edge_curved=False,\n",
        "    figsize=(8, 8),\n",
        "    edge_threshold=0.0,\n",
        "    vertex_color=\"skyblue\",\n",
        "    edge_color=\"gray\",\n",
        "    top_n_labels=20\n",
        "):\n",
        "    import igraph as ig\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "\n",
        "    # Convert adjacency matrix to numpy array\n",
        "    adj = np.array(adjacency_matrix)\n",
        "    n = adj.shape[0]\n",
        "\n",
        "    # Set edge weights below the threshold to 0\n",
        "    adj = np.where(adj > edge_threshold, adj, 0)\n",
        "\n",
        "    # Create igraph graph\n",
        "    g = ig.Graph.Weighted_Adjacency(adj.tolist(), mode=ig.ADJ_UNDIRECTED, attr=\"weight\", loops=False)\n",
        "    g.vs[\"name\"] = labels\n",
        "\n",
        "    # Remove isolated nodes\n",
        "    isolated_nodes = [v.index for v in g.vs if g.degree(v) == 0.0]\n",
        "    if isolated_nodes:\n",
        "        g.delete_vertices(isolated_nodes)\n",
        "\n",
        "\n",
        "\n",
        "    # Node labels\n",
        "    # Assuming labels = vocab is passed\n",
        "    if \"name\" in g.vs.attributes():\n",
        "        # Copy from g.vs[\"name\"] to g.vs[\"label\"]\n",
        "        g.vs[\"label\"] = g.vs[\"name\"]\n",
        "    else:\n",
        "        # Fallback if \"name\" attribute is not present\n",
        "        g.vs[\"label\"] = [str(i) for i in range(g.vcount())]\n",
        "    # Assign labels only to the top_n_labels nodes with the highest PageRank\n",
        "    degrees = g.pagerank()\n",
        "    top_indices = np.argsort(degrees)[-top_n_labels:]  # Top top_n_labels items\n",
        "    g.vs[\"label\"] = [\n",
        "        g.vs[i][\"label\"] if i in top_indices else \"\" for i in range(g.vcount())\n",
        "    ]\n",
        "    # Layout\n",
        "    layout = g.layout(layout_type)\n",
        "\n",
        "    # Edge width\n",
        "    edge_weights = g.es[\"weight\"] if \"weight\" in g.es.attributes() else [1]*g.ecount()\n",
        "    if len(edge_weights) > 0 and max(edge_weights) > 0:\n",
        "        edge_widths = [edge_width_scale * (w / max(edge_weights)) for w in edge_weights]\n",
        "    else:\n",
        "        edge_widths = [1 for _ in edge_weights]\n",
        "\n",
        "    # Community detection (e.g., Louvain method, fallback to fastgreedy if Louvain not available)\n",
        "    try:\n",
        "        communities = g.community_multilevel(weights=g.es['weight'] if 'weight' in g.es.attributes() else None)\n",
        "    except AttributeError:\n",
        "        # fallback method\n",
        "        communities = g.community_fastgreedy(weights=g.es['weight'] if 'weight' in g.es.attributes() else None).as_clustering()\n",
        "    membership = communities.membership\n",
        "    import matplotlib\n",
        "    cmap = matplotlib.cm.get_cmap('tab20')\n",
        "    num_colors = cmap.N if hasattr(cmap, \"N\") else 20\n",
        "    comm_vertex_colors = [matplotlib.colors.to_hex(cmap(i % num_colors)) for i in membership]\n",
        "    g.vs[\"color\"] = comm_vertex_colors\n",
        "    # Change node size according to node PageRank\n",
        "    degrees = g.pagerank()\n",
        "    # Specify minimum and maximum sizes for appropriate scaling\n",
        "    min_size = 20\n",
        "    max_size = 80\n",
        "    # Scaling\n",
        "    if degrees:\n",
        "        min_deg = min(degrees)\n",
        "        max_deg = max(degrees) if max(degrees) != min(degrees) else min(degrees) + 1\n",
        "        # Calculate node size\n",
        "        scaled_sizes = [\n",
        "            min_size + (deg - min_deg) / (max_deg - min_deg) * (max_size - min_size)\n",
        "            for deg in degrees\n",
        "        ]\n",
        "    else:\n",
        "        scaled_sizes = [min_size for _ in g.vs]\n",
        "    g.vs[\"size\"] = scaled_sizes\n",
        "\n",
        "    # Redraw based on node size (node size = pagerank)\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "    ig.plot(\n",
        "        g,\n",
        "        target=ax,\n",
        "        layout=layout,\n",
        "        vertex_size=g.vs[\"size\"],\n",
        "        vertex_label=g.vs[\"label\"],\n",
        "        vertex_label_size=vertex_label_size,\n",
        "        vertex_color=g.vs[\"color\"],\n",
        "        edge_width=edge_widths,\n",
        "        edge_color=edge_color,\n",
        "        edge_curved=edge_curved,\n",
        "        bbox=(figsize[0]*100, figsize[1]*100),\n",
        "        margin=40,\n",
        "    )\n",
        "    plt.show()\n",
        "    return g,communities"
      ],
      "metadata": {
        "id": "H0VTSNNb1JyT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 評価指標"
      ],
      "metadata": {
        "id": "YjCZ5UwoQENr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import igraph as ig\n",
        "from scipy import sparse\n",
        "\n",
        "def get_node_metrics_fast(graph, communities):\n",
        "    \"\"\"\n",
        "    High-speed version using matrix operations:\n",
        "    Calculates participation coefficient, z-score, betweenness, and PageRank for all nodes,\n",
        "    and returns a DataFrame containing all results (no filtering).\n",
        "    \"\"\"\n",
        "    # Get community information\n",
        "    membership = np.array(communities.membership)\n",
        "    num_communities = len(communities)\n",
        "    num_nodes = graph.vcount()\n",
        "\n",
        "    # --- 1. Preparation for Speedup: Create Sparse Matrix ---\n",
        "    A = graph.get_adjacency_sparse()\n",
        "\n",
        "    # U: Affiliation matrix\n",
        "    row_indices = np.arange(num_nodes)\n",
        "    col_indices = membership\n",
        "    data = np.ones(num_nodes)\n",
        "    U = sparse.csr_matrix((data, (row_indices, col_indices)), shape=(num_nodes, num_communities))\n",
        "\n",
        "    # K_dist: Degree matrix per community\n",
        "    K_dist = A @ U\n",
        "\n",
        "    # k_i: Total degree of each node\n",
        "    k_i = np.array(A.sum(axis=1)).flatten()\n",
        "\n",
        "    # --- A. Calculate Participation Coefficient ---\n",
        "    k_i_safe = np.where(k_i == 0, 1, k_i)\n",
        "    K_dist_sq = K_dist.power(2)\n",
        "    sum_k_is_sq = np.array(K_dist_sq.sum(axis=1)).flatten()\n",
        "    participation_coeffs = 1.0 - (sum_k_is_sq / (k_i_safe ** 2))\n",
        "    participation_coeffs[k_i == 0] = 0.0\n",
        "\n",
        "    # --- B. Calculate Community-internal Degree (z-score) ---\n",
        "    k_in = np.array(K_dist[np.arange(num_nodes), membership]).flatten()\n",
        "\n",
        "    df_temp = pd.DataFrame({\n",
        "        'comm_id': membership,\n",
        "        'k_in': k_in\n",
        "    })\n",
        "\n",
        "    grouped = df_temp.groupby('comm_id')['k_in']\n",
        "    means = grouped.transform('mean')\n",
        "    stds = grouped.transform('std')\n",
        "    stds = stds.replace(0, 1)\n",
        "\n",
        "    z_scores = (df_temp['k_in'] - means) / stds\n",
        "    z_scores = z_scores.fillna(0).values\n",
        "\n",
        "    # --- C. Consolidate Data ---\n",
        "\n",
        "    # Calculate PageRank, etc.\n",
        "    degree = k_i\n",
        "    betweenness = graph.betweenness()\n",
        "    pagerank = graph.pagerank()\n",
        "\n",
        "    # Create DataFrame including all nodes\n",
        "    df = pd.DataFrame({\n",
        "        \"name\": graph.vs[\"name\"],\n",
        "        \"community_id\": membership, # This will contain Louvain results (0, 1, 2...)\n",
        "        \"degree\": degree,\n",
        "        \"pagerank\": pagerank,\n",
        "        \"betweenness\": betweenness,\n",
        "        \"z_score\": z_scores,\n",
        "        \"participation\": participation_coeffs\n",
        "    })\n",
        "\n",
        "    # No filtering is done here; all data is returned\n",
        "    return df\n",
        "\n",
        "\n",
        "def get_top10_per_community(graph, communities):\n",
        "    \"\"\"\n",
        "    1. Calculate metrics for all nodes at once.\n",
        "    2. Extract the top 10 nodes per community, ordered by importance (here, degree).\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Calculate for all nodes (no loops are used)\n",
        "    all_nodes_df = get_node_metrics_fast(graph, communities)\n",
        "\n",
        "    # 2. Use Pandas functionality to extract \"top 10 per community\"\n",
        "    #    If you want to change the sorting order, change to by=\"pagerank\", etc.\n",
        "    final_df = (\n",
        "        all_nodes_df\n",
        "        .sort_values([\"community_id\", \"degree\"], ascending=[True, False])\n",
        "        .groupby(\"community_id\")\n",
        "        .head(10)  # Get the top 10 items for each group\n",
        "    )\n",
        "\n",
        "    return final_df,all_nodes_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "Pv71AGv21U5s",
        "outputId": "aba72708-20dc-44fc-ed9c-e7a6423be602"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'igraph'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-675617331.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0migraph\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'igraph'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_network_scatter(df,\n",
        "                         x_col=\"degree\",\n",
        "                         y_col=\"betweenness\",\n",
        "                         hue_col=\"community_id\",\n",
        "                         size_col=\"pagerank\",\n",
        "                         name_col=\"name\",        # Added: Column name containing node names\n",
        "                         label_threshold_x=None,\n",
        "                         figsize=(12, 8)):\n",
        "    \"\"\"\n",
        "    Plots a scatter chart of network metrics and labels points using values from the 'name' column.\n",
        "    \"\"\"\n",
        "\n",
        "    # Prepare the figure\n",
        "    plt.figure(figsize=figsize)\n",
        "\n",
        "    # If community_id, etc. are numerical, convert to string to treat as categorical\n",
        "    plot_df = df.copy()\n",
        "    if hue_col in plot_df.columns:\n",
        "        plot_df[hue_col] = plot_df[hue_col].astype(str)\n",
        "\n",
        "    # Draw the scatter plot\n",
        "    sns.scatterplot(\n",
        "        data=plot_df,\n",
        "        x=x_col,\n",
        "        y=y_col,\n",
        "        hue=hue_col,\n",
        "        size=size_col,\n",
        "        sizes=(50, 600),\n",
        "        alpha=0.7,\n",
        "        palette=\"tab10\",\n",
        "        edgecolor=\"black\"\n",
        "    )\n",
        "\n",
        "    # --- Labeling process (modified part) ---\n",
        "    if label_threshold_x is not None:\n",
        "        # Extract only rows that satisfy the threshold condition\n",
        "        labels_df = df[df[y_col] >= label_threshold_x]\n",
        "\n",
        "        # Loop through each row (get info from row, not just index)\n",
        "        for _, row in labels_df.iterrows():\n",
        "            plt.text(\n",
        "                x=row[x_col],\n",
        "                y=row[y_col],\n",
        "                s=row[name_col],  # Modified: Use the value from the specified column (name)\n",
        "                fontsize=13,\n",
        "                color='black',\n",
        "                fontweight='bold',\n",
        "                ha='right',\n",
        "                va='bottom'\n",
        "            )\n",
        "\n",
        "    # Set grid and title\n",
        "    plt.title(f\"Network Metrics: {x_col} vs {y_col}\", fontsize=20)\n",
        "    plt.xlabel(x_col, fontsize=20)\n",
        "    plt.ylabel(y_col, fontsize=20)\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "    # Move legend outside the plot area\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0,fontsize=20)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "i3ncInDV1U87"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hist_dist(df):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    # Plot histogram\n",
        "    plt.hist(df['degree'], bins=50, log=True, color='skyblue', edgecolor='black')\n",
        "    plt.xlabel(\"Degree (log scale)\",fontsize=20) # Plot axis itself with log transform if necessary\n",
        "    plt.ylabel(\"Frequency (log scale)\",fontsize=20)\n",
        "    plt.title(\"Degree Distribution (Log-Log Scale)\",fontsize=20)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "tuNecDix1U_Y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_community_violin(df,\n",
        "                          x_col=\"community_id\",\n",
        "                          y_col=\"pagerank\",\n",
        "                          figsize=(12, 6),\n",
        "                          fontsize_title=20,\n",
        "                          fontsize_label=20,\n",
        "                          fontsize_tick=20):\n",
        "    # Set figure size\n",
        "    plt.figure(figsize=figsize)\n",
        "\n",
        "    plot_df = df.copy()\n",
        "    if x_col in plot_df.columns:\n",
        "        plot_df[x_col] = plot_df[x_col].astype(str)\n",
        "\n",
        "    sns.violinplot(\n",
        "        data=plot_df,\n",
        "        x=x_col,\n",
        "        y=y_col,\n",
        "        palette=\"Set3\",\n",
        "        inner=None,\n",
        "        linewidth=1\n",
        "    )\n",
        "\n",
        "    # 2. Stripplot (scatter actual data points)\n",
        "    # Overlaying this allows for intuitive understanding of data density and count.\n",
        "    sns.stripplot(\n",
        "        data=plot_df,\n",
        "        x=x_col,\n",
        "        y=y_col,\n",
        "        color='black',\n",
        "        alpha=0.3, # Transparency of points\n",
        "        size=3     # Size of points\n",
        "    )\n",
        "    plt.title(f\"Distribution of {y_col} by {x_col}\", fontsize=fontsize_title)\n",
        "\n",
        "    # Font size for X-axis and Y-axis labels (e.g., \"community_id\")\n",
        "    plt.xlabel(x_col, fontsize=fontsize_label)\n",
        "    plt.ylabel(y_col, fontsize=fontsize_label)\n",
        "\n",
        "    # Font size for ticks (numbers or category names on axes)\n",
        "    plt.tick_params(axis='both', which='major', labelsize=fontsize_tick)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "3Ib6J5Gw1VCF"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}